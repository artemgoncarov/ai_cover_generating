{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install torchaudio\n",
    "!pip install torch diffusers\n",
    "!pip install torchvision\n",
    "!pip install transformers\n",
    "!pip install accelerate\n",
    "!pip install translate\n",
    "!pip install rutube-downloader m3u8 alive_progress\n",
    "!pip install opencv-python\n",
    "!pip install beautifulsoup4\n",
    "!pip install detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pyyaml\n",
    "import sys, os, distutils.core\n",
    "!git clone \"https://github.com/facebookresearch/detectron2\"\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
    "!git clone https://github.com/AlexeyAB/darknet\n",
    "%cd darknet\n",
    "!sed -i \"s/OPENCV=0/OPENCV=1/\" Makefile\n",
    "!sed -i \"s/GPU=0/GPU=1/\" Makefile\n",
    "!sed -i \"s/CUDNN=0/CUDNN=1/\" Makefile\n",
    "!sed -i \"s/CUDNN_HALF=0/CUDNN_HALF=1/\" Makefile\n",
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from translate import Translator\n",
    "from flask import Flask, render_template, request, redirect, jsonify\n",
    "import requests\n",
    "from rutube import Rutube\n",
    "from bs4 import BeautifulSoup\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import os, json, random\n",
    "#from google.colab.patches import cv2_imshow\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = ['person\\n', 'bicycle\\n', 'car\\n', 'motorbike\\n', 'aeroplane\\n', 'bus\\n', 'train\\n', 'truck\\n', 'boat\\n', 'traffic light\\n', 'fire hydrant\\n', 'stop sign\\n', 'parking meter\\n', 'bench\\n', 'bird\\n', 'cat\\n', 'dog\\n', 'horse\\n', 'sheep\\n', 'cow\\n', 'elephant\\n', 'bear\\n', 'zebra\\n', 'giraffe\\n', 'backpack\\n', 'umbrella\\n', 'handbag\\n', 'tie\\n', 'suitcase\\n', 'frisbee\\n', 'skis\\n', 'snowboard\\n', 'sports ball\\n', 'kite\\n', 'baseball bat\\n', 'baseball glove\\n', 'skateboard\\n', 'surfboard\\n', 'tennis racket\\n', 'bottle\\n', 'wine glass\\n', 'cup\\n', 'fork\\n', 'knife\\n', 'spoon\\n', 'bowl\\n', 'banana\\n', 'apple\\n', 'sandwich\\n', 'orange\\n', 'broccoli\\n', 'carrot\\n', 'hot dog\\n', 'pizza\\n', 'donut\\n', 'cake\\n', 'chair\\n', 'sofa\\n', 'pottedplant\\n', 'bed\\n', 'diningtable\\n', 'toilet\\n', 'tvmonitor\\n', 'laptop\\n', 'mouse\\n', 'remote\\n', 'keyboard\\n', 'cell phone\\n', 'microwave\\n', 'oven\\n', 'toaster\\n', 'sink\\n', 'refrigerator\\n', 'book\\n', 'clock\\n', 'vase\\n', 'scissors\\n', 'teddy bear\\n', 'hair drier\\n', 'toothbrush\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = ''\n",
    "prompt = ''\n",
    "path = ''\n",
    "description = ''\n",
    "title = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = title\n",
    "file_name = path\n",
    "description = description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import randint\n",
    "import shutil\n",
    "\n",
    "\n",
    "def split_video(video_path):\n",
    "    file_name = video_path.rstrip('.mp4')\n",
    "    os.mkdir('/content/Frames')\n",
    "    video = cv2.VideoCapture(f'/content/{video_path}')\n",
    "    frame_count = 0\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_interval = total_frames // 60\n",
    "    count = 0\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count % 60 == 0:\n",
    "            cv2.waitKey(1)\n",
    "            cv2.imwrite(fr\"/content/Frames/{count}.jpg\", frame)\n",
    "            count += 1\n",
    "        frame_count += 1\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return frame_interval\n",
    "    # shutil.rmtree('c:\\sochi\\Frames')\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(from_lang='ru', to_lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = input('1. У меня есть файл видео\\n2. У меня есть ссылка на видео\\n3. Поиск для автора\\n')\n",
    "\n",
    "if inp == '1':\n",
    "  file_name = input('Введите путь до файла: ')\n",
    "  description = input('Введите описание видео: ')\n",
    "  wish = input('Введите свои пожелания: ')\n",
    "  text = input('Введите желаемый текст для картинки: ')\n",
    "  models = {\n",
    "            'anime': 'hakurei/waifu-diffusion',\n",
    "            '3d': 'runwayml/stable-diffusion-v1-5',\n",
    "            'realistic': 'CompVis/stable-diffusion-v1-4'\n",
    "  }\n",
    "  model_id = models[input('Введите стиль картинки: realistic, anime, 3d\\n')]\n",
    "  prompt = wish\n",
    "  pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to('cuda')\n",
    "  frame_interval = split_video(file_name)\n",
    "\n",
    "  !wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
    "  counts_dict = {}\n",
    "  from google.colab.patches import cv2_imshow\n",
    "  path = '/content/Frames/'\n",
    "  for i in range(frame_interval):\n",
    "      im = cv2.imread(f'{path}{i}.jpg')\n",
    "      cfg = get_cfg()\n",
    "      # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "      cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "      cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # set threshold for this model\n",
    "      # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "      cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "      predictor = DefaultPredictor(cfg)\n",
    "      outputs = predictor(im)\n",
    "      v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "      out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "      for i in list(outputs[\"instances\"].pred_classes):\n",
    "          if f'{nums[i]}' not in counts_dict.keys():\n",
    "            counts_dict[f'{nums[i]}'] = 0\n",
    "          counts_dict[f'{nums[i]}'] += 1\n",
    "      cv2_imshow(out.get_image()[:, :, ::-1])\n",
    "  shutil.rmtree('/content/Frames')\n",
    "  sorted_dict = [i[0] for i in sorted(counts_dict.items()) if i[1] > 5][:5]\n",
    "  prompt += ' '.join(sorted_dict)\n",
    "  with autocast(\"cuda\"):\n",
    "    image = pipe(prompt, guidance_scale=6)[\"images\"][0]\n",
    "    image.save(f\"/content/image.png\")\n",
    "    img = Image.open('/content/image.png')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    x, y = img.size\n",
    "    font = ImageFont.truetype('/content/News.ttf', choose_font_size(x, y))\n",
    "    width = font.getlength(text)\n",
    "    pos = (x - width) / 2\n",
    "    draw.text((pos, y * 0.75), translator.translate(text), (255, 255, 255), font=font)\n",
    "    img.save(f'/content/sample-out.jpg')\n",
    "    cv2_imshow(cv2.imread(f'/content/sample-out.jpg'))\n",
    "elif inp == '2':\n",
    "  link = input('Введите ссылку на видео: ')\n",
    "  rt = Rutube(link)\n",
    "  rt.playlist[-1].download()\n",
    "  html = requests.get(link).text\n",
    "  soup = BeautifulSoup(html, 'lxml')\n",
    "  title = soup.find(class_='video-pageinfo-container-module__videoTitle').next.next.next\n",
    "  file_name = f'{title}.mp4'\n",
    "  models = {\n",
    "            'anime': 'hakurei/waifu-diffusion',\n",
    "            '3d': 'runwayml/stable-diffusion-v1-5',\n",
    "            'realistic': 'CompVis/stable-diffusion-v1-4'\n",
    "  }\n",
    "  model_id = models[input('Введите стиль картинки: realistic, anime, 3d\\n')]\n",
    "  text = input('Введите желаемый текст для картинки: ')\n",
    "  wish = input('Введите пожелания к видео: ')\n",
    "  description = input('Введите описание к видео: ')\n",
    "  category = html[html.find(\"category_url\") + 12:]\n",
    "  category = category[:category.find(\"}\")]\n",
    "  category = category[category.find(\"name\")+5:]\n",
    "  category = category[category.find(\"\\\"\")+1:category.rfind(\"\\\"\")]\n",
    "  prompt = ' '.join([wish, category, title])\n",
    "  file_name = f'/content/{i}.mp4'\n",
    "  prompt = ' '.join([wish, description])\n",
    "  prompt = translator.translate(prompt)\n",
    "  pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to('cuda')\n",
    "  frame_interval = split_video(file_name)\n",
    "\n",
    "  !wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
    "  counts_dict = {}\n",
    "  from google.colab.patches import cv2_imshow\n",
    "  path = '/content/Frames/'\n",
    "  for i in range(frame_interval):\n",
    "      im = cv2.imread(f'{path}{i}.jpg')\n",
    "      cfg = get_cfg()\n",
    "      # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "      cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "      cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # set threshold for this model\n",
    "      # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "      cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "      predictor = DefaultPredictor(cfg)\n",
    "      outputs = predictor(im)\n",
    "      v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "      out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "      for i in list(outputs[\"instances\"].pred_classes):\n",
    "          if f'{nums[i]}' not in counts_dict.keys():\n",
    "            counts_dict[f'{nums[i]}'] = 0\n",
    "          counts_dict[f'{nums[i]}'] += 1\n",
    "      cv2_imshow(out.get_image()[:, :, ::-1])\n",
    "  shutil.rmtree('/content/Frames')\n",
    "  sorted_dict = [i[0] for i in sorted(counts_dict.items()) if i[1] > 5][:5]\n",
    "  prompt += ' '.join(sorted_dict)\n",
    "  with autocast(\"cuda\"):\n",
    "    image = pipe(prompt, guidance_scale=6)[\"images\"][0]\n",
    "    image.save(f\"/content/image.png\")\n",
    "    img = Image.open('/content/image.png')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    x, y = img.size\n",
    "    font = ImageFont.truetype('/content/News.ttf', choose_font_size(x, y))\n",
    "    width = font.getlength(text)\n",
    "    pos = (x - width) / 2\n",
    "    draw.text((pos, y * 0.75), translator.translate(text), (255, 255, 255), font=font)\n",
    "    img.save(f'/content/sample-out.jpg')\n",
    "    cv2_imshow(cv2.imread(f'/content/sample-out.jpg'))\n",
    "else:\n",
    "  dicts = []\n",
    "  author = input('Введите имя автора: ')\n",
    "  wish = input('Пожелания: ')\n",
    "  theme = input('Тематика канала: ')\n",
    "  text = input('Желаемый текст к картинке: ')\n",
    "  models = {\n",
    "            'anime': 'hakurei/waifu-diffusion',\n",
    "            '3d': 'runwayml/stable-diffusion-v1-5',\n",
    "            'realistic': 'CompVis/stable-diffusion-v1-4'\n",
    "  }\n",
    "  model_id = models[input('Введите стиль картинки: realistic, anime, 3d\\n')]\n",
    "  prompt = ' '.join([wish, theme])\n",
    "  prompt = translator.translate(prompt)\n",
    "  d = dict()\n",
    "  for i in range(0, data.shape[0]):\n",
    "    try:\n",
    "      d[data.channel_title[i]].append(i)\n",
    "    except:\n",
    "      d[data.channel_title[i]] = [i]\n",
    "  author_ids = d[author]\n",
    "  for id in author_ids:\n",
    "    file_name = f'/content/{id}.mp4'\n",
    "    prompt = ' '.join([wish, description])\n",
    "    prompt = translator.translate(prompt)\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to('cuda')\n",
    "    frame_interval = split_video(file_name)\n",
    "\n",
    "    !wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
    "    counts_dict = {}\n",
    "    from google.colab.patches import cv2_imshow\n",
    "    path = '/content/Frames/'\n",
    "    for i in range(frame_interval):\n",
    "        im = cv2.imread(f'{path}{i}.jpg')\n",
    "        cfg = get_cfg()\n",
    "        # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # set threshold for this model\n",
    "        # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "        predictor = DefaultPredictor(cfg)\n",
    "        outputs = predictor(im)\n",
    "        v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        for i in list(outputs[\"instances\"].pred_classes):\n",
    "            if f'{nums[i]}' not in counts_dict.keys():\n",
    "              counts_dict[f'{nums[i]}'] = 0\n",
    "            counts_dict[f'{nums[i]}'] += 1\n",
    "        cv2_imshow(out.get_image()[:, :, ::-1])\n",
    "    shutil.rmtree('/content/Frames')\n",
    "    dicts.append(counts_dict)\n",
    "\n",
    "  for num_dict in range(1, len(dicts)):\n",
    "    for cnts in dicts[num_dict]:\n",
    "        if cnts not in dicts[0]:\n",
    "            dicts[0][cnts] = dicts[num_dict][cnts]\n",
    "        dicts[0][cnts] += 1\n",
    "  sorted_dict = [i[0] for i in sorted(dicts[0].items()) if i[1] > 15][:5]\n",
    "  prompt = ' '.join(sorted_dict) + ' ' + theme\n",
    "  pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to('cuda')\n",
    "  with autocast(\"cuda\"):\n",
    "    image = pipe(prompt, guidance_scale=6)[\"images\"][0]\n",
    "    image.save(f\"/content/image.png\")\n",
    "    img = Image.open('/content/image.png')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    x, y = img.size\n",
    "    font = ImageFont.truetype('/content/News.ttf', choose_font_size(x, y))\n",
    "    width = font.getlength(text)\n",
    "    pos = (x - width) / 2\n",
    "    draw.text((pos, y * 0.75), translator.translate(text), (255, 255, 255), font=font)\n",
    "    img.save(f'/content/sample-out.jpg')\n",
    "    cv2_imshow(cv2.imread(f'/content/sample-out.jpg'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
